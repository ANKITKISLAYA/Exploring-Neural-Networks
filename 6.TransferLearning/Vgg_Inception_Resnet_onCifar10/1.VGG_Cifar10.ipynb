{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89c4675-a833-4e81-a2bc-7b0f914baf0d",
   "metadata": {},
   "source": [
    "#### Using Bottleneck features of Vgg_cifar10 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7121b-fdef-423e-9d60-f1d2616755b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8acb75c8-5261-446c-abef-280af2952b09",
   "metadata": {},
   "source": [
    "#### Exploring our vgg_cifar10_bottleneck_features_train.p and vgg_cifar10_bottleneck_features_validation.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00a8bb9-f691-415e-871c-d927fdc3146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections, numpy as np\n",
    "\n",
    "training_file = \"vgg_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"vgg_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "with open(training_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(validation_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197f68e4-5b4a-4dba-b950-917a06dae9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bottleneck features shape :- (40000, 1, 1, 512)\n",
      "Training Bottleneck labels shape :- (40000, 1)\n",
      "Validation Bottleneck features shape :- (10000, 1, 1, 512)\n",
      "Validation Bottleneck labels shape :- (10000, 1)\n",
      "Unique Classes :- [0 1 2 3 4 5 6 7 8 9]\n",
      "Number of Examples in each Class :- Counter({6: 4047, 4: 4033, 1: 4014, 8: 4011, 7: 4001, 0: 3996, 5: 3984, 2: 3984, 3: 3970, 9: 3960})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Bottleneck features shape :-\",train_data['features'].shape)\n",
    "print(\"Training Bottleneck labels shape :-\",train_data['labels'].shape)\n",
    "print(\"Validation Bottleneck features shape :-\",validation_data['features'].shape)\n",
    "print(\"Validation Bottleneck labels shape :-\",validation_data['labels'].shape)\n",
    "print(\"Unique Classes :-\", np.unique(train_data['labels']))\n",
    "labels = train_data['labels'].reshape(train_data['labels'].shape[0])\n",
    "counter = collections.Counter(labels)\n",
    "print(\"Number of Examples in each Class :-\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c81aa8-7f4c-47f0-b7a6-abcbba143983",
   "metadata": {},
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562bd8da-4069-417b-9f6d-5d088613357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akislaya\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7563295-75af-4a3a-9396-2299ff1d9eae",
   "metadata": {},
   "source": [
    "#### Function to extract and load bottleneck data from training_file and validation_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1571718-d154-4769-8658-4ae9d86b96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da185651-0f5e-4f08-8505-c292e956d269",
   "metadata": {},
   "source": [
    "#### Building and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68b7a41-2ba9-4edb-ae83-4fe863398b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file vgg_cifar10_bottleneck_features_train.p\n",
      "Validation file vgg_cifar10_bottleneck_features_validation.p\n",
      "(40000, 1, 1, 512) (40000, 1)\n",
      "(10000, 1, 1, 512) (10000, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,130\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_file = \"vgg_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"vgg_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "# load bottleneck data\n",
    "X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "# defining number of classes and hyperparams below\n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "    \n",
    "# Building the model \n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=input_shape))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(n_classes,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c75f33-3d53-466a-82dd-d8ffffff9f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 1.5763 - acc: 0.5559 - val_loss: 0.7868 - val_acc: 0.7373\n",
      "Epoch 2/50\n",
      "  256/40000 [..............................] - ETA: 0s - loss: 0.8020 - acc: 0.7266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akislaya\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 13us/sample - loss: 0.6714 - acc: 0.7749 - val_loss: 0.5921 - val_acc: 0.7961\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.5422 - acc: 0.8149 - val_loss: 0.5178 - val_acc: 0.8198\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.4832 - acc: 0.8359 - val_loss: 0.4788 - val_acc: 0.8360\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.4467 - acc: 0.8461 - val_loss: 0.4655 - val_acc: 0.8367\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.4256 - acc: 0.8541 - val_loss: 0.4417 - val_acc: 0.8477\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.4064 - acc: 0.8602 - val_loss: 0.4324 - val_acc: 0.8504\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3947 - acc: 0.8641 - val_loss: 0.4257 - val_acc: 0.8516\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 14us/sample - loss: 0.3844 - acc: 0.8677 - val_loss: 0.4234 - val_acc: 0.8559\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 0s 10us/sample - loss: 0.3784 - acc: 0.8697 - val_loss: 0.4238 - val_acc: 0.8560\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3720 - acc: 0.8721 - val_loss: 0.4196 - val_acc: 0.8572\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 0s 10us/sample - loss: 0.3647 - acc: 0.8735 - val_loss: 0.4203 - val_acc: 0.8557\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3625 - acc: 0.8754 - val_loss: 0.4188 - val_acc: 0.8571\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3577 - acc: 0.8770 - val_loss: 0.4137 - val_acc: 0.8581\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3533 - acc: 0.8774 - val_loss: 0.4113 - val_acc: 0.8588\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3504 - acc: 0.8781 - val_loss: 0.4230 - val_acc: 0.8547\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3492 - acc: 0.8777 - val_loss: 0.4163 - val_acc: 0.8591\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3466 - acc: 0.8780 - val_loss: 0.4151 - val_acc: 0.8562\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3443 - acc: 0.8801 - val_loss: 0.4191 - val_acc: 0.8536\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3416 - acc: 0.8806 - val_loss: 0.4081 - val_acc: 0.8610\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3417 - acc: 0.8799 - val_loss: 0.4135 - val_acc: 0.8595\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3384 - acc: 0.8813 - val_loss: 0.4151 - val_acc: 0.8607\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3387 - acc: 0.8820 - val_loss: 0.4172 - val_acc: 0.8581\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3402 - acc: 0.8808 - val_loss: 0.4197 - val_acc: 0.8577\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3377 - acc: 0.8812 - val_loss: 0.4157 - val_acc: 0.8611\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3378 - acc: 0.8818 - val_loss: 0.4264 - val_acc: 0.8566\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3368 - acc: 0.8825 - val_loss: 0.4218 - val_acc: 0.8582\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3345 - acc: 0.8819 - val_loss: 0.4235 - val_acc: 0.8601\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3329 - acc: 0.8830 - val_loss: 0.4157 - val_acc: 0.8597\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3326 - acc: 0.8820 - val_loss: 0.4366 - val_acc: 0.8509\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3325 - acc: 0.8834 - val_loss: 0.4244 - val_acc: 0.8556\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3300 - acc: 0.8840 - val_loss: 0.4294 - val_acc: 0.8571\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3316 - acc: 0.8836 - val_loss: 0.4239 - val_acc: 0.8572\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3317 - acc: 0.8834 - val_loss: 0.4262 - val_acc: 0.8564\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3312 - acc: 0.8834 - val_loss: 0.4302 - val_acc: 0.8583\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3292 - acc: 0.8843 - val_loss: 0.4324 - val_acc: 0.8530\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3328 - acc: 0.8829 - val_loss: 0.4355 - val_acc: 0.8567\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3297 - acc: 0.8839 - val_loss: 0.4284 - val_acc: 0.8576\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3290 - acc: 0.8840 - val_loss: 0.4294 - val_acc: 0.8553\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 0s 10us/sample - loss: 0.3294 - acc: 0.8837 - val_loss: 0.4290 - val_acc: 0.8551\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 0s 12us/sample - loss: 0.3291 - acc: 0.8841 - val_loss: 0.4315 - val_acc: 0.8539\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 0s 10us/sample - loss: 0.3273 - acc: 0.8838 - val_loss: 0.4332 - val_acc: 0.8537\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 0s 10us/sample - loss: 0.3270 - acc: 0.8838 - val_loss: 0.4277 - val_acc: 0.8582\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3270 - acc: 0.8840 - val_loss: 0.4312 - val_acc: 0.8558\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 0s 11us/sample - loss: 0.3288 - acc: 0.8835 - val_loss: 0.4354 - val_acc: 0.8527\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 0s 10us/sample - loss: 0.3283 - acc: 0.8844 - val_loss: 0.4364 - val_acc: 0.8541\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 15us/sample - loss: 0.3286 - acc: 0.8835 - val_loss: 0.4332 - val_acc: 0.8557\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 0s 9us/sample - loss: 0.3263 - acc: 0.8861 - val_loss: 0.4344 - val_acc: 0.8548\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 0s 9us/sample - loss: 0.3256 - acc: 0.8849 - val_loss: 0.4381 - val_acc: 0.8537\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 0s 9us/sample - loss: 0.3268 - acc: 0.8839 - val_loss: 0.4344 - val_acc: 0.8562\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics= ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size,epochs, validation_data=(X_val, y_val),shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27a9a3-e7de-436b-8d06-3bd8915e8899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d550c95-00c4-48ab-982c-f35efcbf58f4",
   "metadata": {},
   "source": [
    "#### Below is the handy code to get current directory. This will make sure our training and validation file are in same folder as our notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090588dc-1c43-46a0-aed2-c3c1bd1729b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\akislaya\\\\Anaconda Files\\\\CAV\\\\TransferLearning\\\\CarND-Transfer-Learning-Lab-master\\\\VGG\\\\Vgg_Inception_Resnet_onCifar10': ['.ipynb_checkpoints', '1.VGG_Cifar10.ipynb', '2.Resnet_Cifar10.ipynb', '3.Inception_Cifar10.ipynb', 'inception_cifar10_bottleneck_features_train.p', 'inception_cifar10_bottleneck_features_validation.p', 'resnet_cifar10_bottleneck_features_train.p', 'resnet_cifar10_bottleneck_features_validation.p', 'vgg_cifar10_bottleneck_features_train.p', 'vgg_cifar10_bottleneck_features_validation.p']\n"
     ]
    }
   ],
   "source": [
    "#Code to get current working directory\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582bdf1-e1ab-4e59-8548-037f9de3d2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
