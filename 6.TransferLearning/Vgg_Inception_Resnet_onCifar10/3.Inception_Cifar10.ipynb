{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89c4675-a833-4e81-a2bc-7b0f914baf0d",
   "metadata": {},
   "source": [
    "#### Using Bottleneck features of Inception_cifar10 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7121b-fdef-423e-9d60-f1d2616755b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8acb75c8-5261-446c-abef-280af2952b09",
   "metadata": {},
   "source": [
    "#### Exploring our Inception_cifar10_bottleneck_features_train.p and Inception_cifar10_bottleneck_features_validation.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00a8bb9-f691-415e-871c-d927fdc3146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections, numpy as np\n",
    "\n",
    "training_file = \"inception_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"inception_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "with open(training_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(validation_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197f68e4-5b4a-4dba-b950-917a06dae9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bottleneck features shape :- (40000, 1, 1, 2048)\n",
      "Training Bottleneck labels shape :- (40000, 1)\n",
      "Validation Bottleneck features shape :- (10000, 1, 1, 2048)\n",
      "Validation Bottleneck labels shape :- (10000, 1)\n",
      "Unique Classes :- [0 1 2 3 4 5 6 7 8 9]\n",
      "Number of Examples in each Class :- Counter({6: 4047, 4: 4033, 1: 4014, 8: 4011, 7: 4001, 0: 3996, 5: 3984, 2: 3984, 3: 3970, 9: 3960})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Bottleneck features shape :-\",train_data['features'].shape)\n",
    "print(\"Training Bottleneck labels shape :-\",train_data['labels'].shape)\n",
    "print(\"Validation Bottleneck features shape :-\",validation_data['features'].shape)\n",
    "print(\"Validation Bottleneck labels shape :-\",validation_data['labels'].shape)\n",
    "print(\"Unique Classes :-\", np.unique(train_data['labels']))\n",
    "labels = train_data['labels'].reshape(train_data['labels'].shape[0])\n",
    "counter = collections.Counter(labels)\n",
    "print(\"Number of Examples in each Class :-\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c81aa8-7f4c-47f0-b7a6-abcbba143983",
   "metadata": {},
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562bd8da-4069-417b-9f6d-5d088613357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akislaya\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7563295-75af-4a3a-9396-2299ff1d9eae",
   "metadata": {},
   "source": [
    "#### Function to extract and load bottleneck data from training_file and validation_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1571718-d154-4769-8658-4ae9d86b96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da185651-0f5e-4f08-8505-c292e956d269",
   "metadata": {},
   "source": [
    "#### Building and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68b7a41-2ba9-4edb-ae83-4fe863398b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file inception_cifar10_bottleneck_features_train.p\n",
      "Validation file inception_cifar10_bottleneck_features_validation.p\n",
      "(40000, 1, 1, 2048) (40000, 1)\n",
      "(10000, 1, 1, 2048) (10000, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,490\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_file = \"inception_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"inception_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "# load bottleneck data\n",
    "X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "# defining number of classes and hyperparams below\n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "    \n",
    "# Building the model \n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=input_shape))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(n_classes,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c75f33-3d53-466a-82dd-d8ffffff9f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 25us/sample - loss: 1.0129 - acc: 0.6582 - val_loss: 0.7737 - val_acc: 0.7366\n",
      "Epoch 2/50\n",
      "  256/40000 [..............................] - ETA: 1s - loss: 0.6792 - acc: 0.7461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akislaya\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 16us/sample - loss: 0.7265 - acc: 0.7584 - val_loss: 0.7112 - val_acc: 0.7545\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.6602 - acc: 0.7801 - val_loss: 0.6801 - val_acc: 0.7651\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.6197 - acc: 0.7933 - val_loss: 0.6631 - val_acc: 0.7724\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.5910 - acc: 0.8025 - val_loss: 0.6559 - val_acc: 0.7761\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.5681 - acc: 0.8104 - val_loss: 0.6512 - val_acc: 0.7737\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.5502 - acc: 0.8145 - val_loss: 0.6511 - val_acc: 0.7746\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.5357 - acc: 0.8215 - val_loss: 0.6453 - val_acc: 0.7763\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 25us/sample - loss: 0.5227 - acc: 0.8257 - val_loss: 0.6428 - val_acc: 0.7776\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.5112 - acc: 0.8288 - val_loss: 0.6430 - val_acc: 0.7792\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.5013 - acc: 0.8317 - val_loss: 0.6450 - val_acc: 0.7768\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4921 - acc: 0.8361 - val_loss: 0.6473 - val_acc: 0.7762\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4856 - acc: 0.8365 - val_loss: 0.6495 - val_acc: 0.7782\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4777 - acc: 0.8410 - val_loss: 0.6508 - val_acc: 0.7769\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4714 - acc: 0.8418 - val_loss: 0.6518 - val_acc: 0.7762\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.4652 - acc: 0.8432 - val_loss: 0.6530 - val_acc: 0.7761\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4594 - acc: 0.8461 - val_loss: 0.6534 - val_acc: 0.7784\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4541 - acc: 0.8476 - val_loss: 0.6572 - val_acc: 0.7754\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 1s 15us/sample - loss: 0.4487 - acc: 0.8517 - val_loss: 0.6591 - val_acc: 0.7767\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 15us/sample - loss: 0.4452 - acc: 0.8508 - val_loss: 0.6608 - val_acc: 0.7757\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4405 - acc: 0.8513 - val_loss: 0.6678 - val_acc: 0.7740\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.4367 - acc: 0.8542 - val_loss: 0.6677 - val_acc: 0.7735\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4322 - acc: 0.8558 - val_loss: 0.6690 - val_acc: 0.7733\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.4293 - acc: 0.8562 - val_loss: 0.6727 - val_acc: 0.7757\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 20us/sample - loss: 0.4255 - acc: 0.8587 - val_loss: 0.6739 - val_acc: 0.7731\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4224 - acc: 0.8590 - val_loss: 0.6794 - val_acc: 0.7725\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4196 - acc: 0.8594 - val_loss: 0.6777 - val_acc: 0.7714\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4162 - acc: 0.8611 - val_loss: 0.6826 - val_acc: 0.7710\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4133 - acc: 0.8622 - val_loss: 0.6856 - val_acc: 0.7710\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4116 - acc: 0.8627 - val_loss: 0.6864 - val_acc: 0.7711\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4085 - acc: 0.8637 - val_loss: 0.6944 - val_acc: 0.7673\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4067 - acc: 0.8642 - val_loss: 0.6954 - val_acc: 0.7682\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4041 - acc: 0.8652 - val_loss: 0.6959 - val_acc: 0.7689\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4021 - acc: 0.8652 - val_loss: 0.6968 - val_acc: 0.7700\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.3997 - acc: 0.8684 - val_loss: 0.7018 - val_acc: 0.7702\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.3977 - acc: 0.8680 - val_loss: 0.7036 - val_acc: 0.7695\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.3959 - acc: 0.8679 - val_loss: 0.7076 - val_acc: 0.7663\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 1s 18us/sample - loss: 0.3934 - acc: 0.8690 - val_loss: 0.7106 - val_acc: 0.7651\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 20us/sample - loss: 0.3919 - acc: 0.8695 - val_loss: 0.7114 - val_acc: 0.7649\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3900 - acc: 0.8699 - val_loss: 0.7170 - val_acc: 0.7654\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3883 - acc: 0.8708 - val_loss: 0.7175 - val_acc: 0.7659\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3875 - acc: 0.8705 - val_loss: 0.7245 - val_acc: 0.7636\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3851 - acc: 0.8716 - val_loss: 0.7264 - val_acc: 0.7629\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.3837 - acc: 0.8712 - val_loss: 0.7278 - val_acc: 0.7623\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.3823 - acc: 0.8727 - val_loss: 0.7308 - val_acc: 0.7638\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3802 - acc: 0.8745 - val_loss: 0.7292 - val_acc: 0.7655\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3788 - acc: 0.8733 - val_loss: 0.7347 - val_acc: 0.7623\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.3768 - acc: 0.8749 - val_loss: 0.7387 - val_acc: 0.7613\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3754 - acc: 0.8755 - val_loss: 0.7374 - val_acc: 0.7609\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3746 - acc: 0.8742 - val_loss: 0.7442 - val_acc: 0.7614\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics= ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size,epochs, validation_data=(X_val, y_val),shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a5a67-a29a-48cd-a7e6-d218fcd66b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d550c95-00c4-48ab-982c-f35efcbf58f4",
   "metadata": {},
   "source": [
    "#### Below is the handy code to get current directory. This will make sure our training and validation file are in same folder as our notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090588dc-1c43-46a0-aed2-c3c1bd1729b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\akislaya\\\\Anaconda Files\\\\CAV\\\\TransferLearning\\\\CarND-Transfer-Learning-Lab-master\\\\VGG\\\\Vgg_Inception_Resnet_onCifar10': ['.ipynb_checkpoints', '1.VGG_Cifar10.ipynb', '2.Resnet_Cifar10.ipynb', '3.Inception_Cifar10.ipynb', 'inception_cifar10_bottleneck_features_train.p', 'inception_cifar10_bottleneck_features_validation.p', 'resnet_cifar10_bottleneck_features_train.p', 'resnet_cifar10_bottleneck_features_validation.p', 'vgg_cifar10_bottleneck_features_train.p', 'vgg_cifar10_bottleneck_features_validation.p']\n"
     ]
    }
   ],
   "source": [
    "#Code to get current working directory\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582bdf1-e1ab-4e59-8548-037f9de3d2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
