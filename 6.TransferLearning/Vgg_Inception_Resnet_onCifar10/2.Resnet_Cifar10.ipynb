{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89c4675-a833-4e81-a2bc-7b0f914baf0d",
   "metadata": {},
   "source": [
    "#### Using Bottleneck features of Resnet_cifar10 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7121b-fdef-423e-9d60-f1d2616755b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8acb75c8-5261-446c-abef-280af2952b09",
   "metadata": {},
   "source": [
    "#### Exploring our Resnet_cifar10_bottleneck_features_train.p and Resnet_cifar10_bottleneck_features_validation.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00a8bb9-f691-415e-871c-d927fdc3146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections, numpy as np\n",
    "\n",
    "training_file = \"resnet_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"resnet_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "with open(training_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(validation_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197f68e4-5b4a-4dba-b950-917a06dae9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bottleneck features shape :- (40000, 1, 1, 2048)\n",
      "Training Bottleneck labels shape :- (40000, 1)\n",
      "Validation Bottleneck features shape :- (10000, 1, 1, 2048)\n",
      "Validation Bottleneck labels shape :- (10000, 1)\n",
      "Unique Classes :- [0 1 2 3 4 5 6 7 8 9]\n",
      "Number of Examples in each Class :- Counter({6: 4047, 4: 4033, 1: 4014, 8: 4011, 7: 4001, 0: 3996, 5: 3984, 2: 3984, 3: 3970, 9: 3960})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Bottleneck features shape :-\",train_data['features'].shape)\n",
    "print(\"Training Bottleneck labels shape :-\",train_data['labels'].shape)\n",
    "print(\"Validation Bottleneck features shape :-\",validation_data['features'].shape)\n",
    "print(\"Validation Bottleneck labels shape :-\",validation_data['labels'].shape)\n",
    "print(\"Unique Classes :-\", np.unique(train_data['labels']))\n",
    "labels = train_data['labels'].reshape(train_data['labels'].shape[0])\n",
    "counter = collections.Counter(labels)\n",
    "print(\"Number of Examples in each Class :-\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c81aa8-7f4c-47f0-b7a6-abcbba143983",
   "metadata": {},
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562bd8da-4069-417b-9f6d-5d088613357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akislaya\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7563295-75af-4a3a-9396-2299ff1d9eae",
   "metadata": {},
   "source": [
    "#### Function to extract and load bottleneck data from training_file and validation_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1571718-d154-4769-8658-4ae9d86b96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da185651-0f5e-4f08-8505-c292e956d269",
   "metadata": {},
   "source": [
    "#### Building and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68b7a41-2ba9-4edb-ae83-4fe863398b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file resnet_cifar10_bottleneck_features_train.p\n",
      "Validation file resnet_cifar10_bottleneck_features_validation.p\n",
      "(40000, 1, 1, 2048) (40000, 1)\n",
      "(10000, 1, 1, 2048) (10000, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,490\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_file = \"resnet_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"resnet_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "# load bottleneck data\n",
    "X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "# defining number of classes and hyperparams below\n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "    \n",
    "# Building the model \n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=input_shape))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(n_classes,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c75f33-3d53-466a-82dd-d8ffffff9f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "39680/40000 [============================>.] - ETA: 0s - loss: 0.8476 - acc: 0.7144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akislaya\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 29us/sample - loss: 0.8457 - acc: 0.7151 - val_loss: 0.6021 - val_acc: 0.7889\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.5380 - acc: 0.8183 - val_loss: 0.5252 - val_acc: 0.8209\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4818 - acc: 0.8351 - val_loss: 0.4933 - val_acc: 0.8300\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.4467 - acc: 0.8460 - val_loss: 0.4836 - val_acc: 0.8318\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.4207 - acc: 0.8579 - val_loss: 0.4839 - val_acc: 0.8318\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.3976 - acc: 0.8650 - val_loss: 0.4658 - val_acc: 0.8385\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.3816 - acc: 0.8708 - val_loss: 0.4587 - val_acc: 0.8410\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3682 - acc: 0.8748 - val_loss: 0.4563 - val_acc: 0.8439\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 16us/sample - loss: 0.3576 - acc: 0.8783 - val_loss: 0.4634 - val_acc: 0.8420\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 19us/sample - loss: 0.3465 - acc: 0.8815 - val_loss: 0.4540 - val_acc: 0.8454\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3380 - acc: 0.8842 - val_loss: 0.4574 - val_acc: 0.8413\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.3280 - acc: 0.8886 - val_loss: 0.4519 - val_acc: 0.8453\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.3219 - acc: 0.8902 - val_loss: 0.4552 - val_acc: 0.8443\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.3118 - acc: 0.8942 - val_loss: 0.4568 - val_acc: 0.8416\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 20us/sample - loss: 0.3045 - acc: 0.8969 - val_loss: 0.4617 - val_acc: 0.8402\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.3009 - acc: 0.8992 - val_loss: 0.4469 - val_acc: 0.8459\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.2921 - acc: 0.9014 - val_loss: 0.4592 - val_acc: 0.8447\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.2892 - acc: 0.9027 - val_loss: 0.4579 - val_acc: 0.8454\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2836 - acc: 0.9060 - val_loss: 0.4535 - val_acc: 0.8449\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.2807 - acc: 0.9047 - val_loss: 0.4491 - val_acc: 0.8474\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.2755 - acc: 0.9079 - val_loss: 0.4685 - val_acc: 0.8430\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.2709 - acc: 0.9099 - val_loss: 0.4605 - val_acc: 0.8440\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.2643 - acc: 0.9120 - val_loss: 0.4694 - val_acc: 0.8427\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 24us/sample - loss: 0.2632 - acc: 0.9119 - val_loss: 0.4706 - val_acc: 0.8421\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2596 - acc: 0.9124 - val_loss: 0.4682 - val_acc: 0.8422\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 23us/sample - loss: 0.2541 - acc: 0.9158 - val_loss: 0.4650 - val_acc: 0.8409\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 17us/sample - loss: 0.2519 - acc: 0.9162 - val_loss: 0.4738 - val_acc: 0.8409\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 18us/sample - loss: 0.2495 - acc: 0.9166 - val_loss: 0.4711 - val_acc: 0.8423\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2466 - acc: 0.9180 - val_loss: 0.4687 - val_acc: 0.8438\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2425 - acc: 0.9196 - val_loss: 0.4795 - val_acc: 0.8434\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2391 - acc: 0.9211 - val_loss: 0.4743 - val_acc: 0.8402\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2372 - acc: 0.9218 - val_loss: 0.4885 - val_acc: 0.8378\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2346 - acc: 0.9212 - val_loss: 0.4814 - val_acc: 0.8420\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2332 - acc: 0.9235 - val_loss: 0.4849 - val_acc: 0.8425\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2291 - acc: 0.9244 - val_loss: 0.4938 - val_acc: 0.8372\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2286 - acc: 0.9248 - val_loss: 0.4852 - val_acc: 0.8408\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2254 - acc: 0.9243 - val_loss: 0.4924 - val_acc: 0.8403\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2231 - acc: 0.9262 - val_loss: 0.4948 - val_acc: 0.8417\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2198 - acc: 0.9271 - val_loss: 0.5032 - val_acc: 0.8367\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2189 - acc: 0.9272 - val_loss: 0.4940 - val_acc: 0.8388\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2175 - acc: 0.9277 - val_loss: 0.5076 - val_acc: 0.8351\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2151 - acc: 0.9281 - val_loss: 0.4998 - val_acc: 0.8412\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2139 - acc: 0.9295 - val_loss: 0.5062 - val_acc: 0.8398\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 1s 22us/sample - loss: 0.2110 - acc: 0.9297 - val_loss: 0.5133 - val_acc: 0.8368\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 20us/sample - loss: 0.2097 - acc: 0.9301 - val_loss: 0.5103 - val_acc: 0.8372\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 18us/sample - loss: 0.2076 - acc: 0.9313 - val_loss: 0.5166 - val_acc: 0.8339\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 20us/sample - loss: 0.2074 - acc: 0.9327 - val_loss: 0.5178 - val_acc: 0.8362\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2036 - acc: 0.9333 - val_loss: 0.5256 - val_acc: 0.8355\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2020 - acc: 0.9337 - val_loss: 0.5167 - val_acc: 0.8403\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 21us/sample - loss: 0.2028 - acc: 0.9339 - val_loss: 0.5199 - val_acc: 0.8364\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics= ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size,epochs, validation_data=(X_val, y_val),shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a5a67-a29a-48cd-a7e6-d218fcd66b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d550c95-00c4-48ab-982c-f35efcbf58f4",
   "metadata": {},
   "source": [
    "#### Below is the handy code to get current directory. This will make sure our training and validation file are in same folder as our notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090588dc-1c43-46a0-aed2-c3c1bd1729b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\akislaya\\\\Anaconda Files\\\\CAV\\\\TransferLearning\\\\CarND-Transfer-Learning-Lab-master\\\\VGG\\\\Vgg_Inception_Resnet_onCifar10': ['.ipynb_checkpoints', '1.VGG_Cifar10.ipynb', '2.Resnet_Cifar10.ipynb', '3.Inception_Cifar10.ipynb', 'inception_cifar10_bottleneck_features_train.p', 'inception_cifar10_bottleneck_features_validation.p', 'resnet_cifar10_bottleneck_features_train.p', 'resnet_cifar10_bottleneck_features_validation.p', 'vgg_cifar10_bottleneck_features_train.p', 'vgg_cifar10_bottleneck_features_validation.p']\n"
     ]
    }
   ],
   "source": [
    "#Code to get current working directory\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49f658-3a84-4963-bf77-6d37de5a7eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
